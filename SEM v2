import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import pymc as pm
import arviz as az
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.metrics import r2_score
from sklearn.model_selection import cross_val_score
from sklearn.impute import KNNImputer
import xgboost as xgb
import shap
import os
import warnings
import logging
import time
from pathlib import Path
import cv2
from skimage import io, measure, morphology
from skimage.morphology import skeletonize, remove_small_holes, remove_small_objects
from skimage.measure import regionprops
from skimage.feature import canny
from skimage import filters
from scipy import ndimage as ndi
from skimage import img_as_ubyte
import pathlib, inspect, os
# 把 results 放到本脚本所在目录
SCRIPT_DIR = pathlib.Path(__file__).resolve().parent
RESULT_DIR = SCRIPT_DIR / "results"
RESULT_DIR.mkdir(exist_ok=True)
Path("results").mkdir(exist_ok=True)
logging.basicConfig(
    filename="results/aerogel_analysis.log",
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    encoding="utf-8"
)
logger = logging.getLogger()
# 这里使用的是绝对路径，更换环境后需要重新配置文件环境
image_paths = [
    "C:/Users/zhaol/Desktop/codexex/polymer_analysis/Aerogel_SEM/20230822_12p_21.tif",
    "C:/Users/zhaol/Desktop/codexex/polymer_analysis/Aerogel_SEM/20230823_13p_17.tif",
    "C:/Users/zhaol/Desktop/codexex/polymer_analysis/Aerogel_SEM/20230824_14p_18.tif",
    "C:/Users/zhaol/Desktop/codexex/polymer_analysis/Aerogel_SEM/20230823_10p_17.tif",
    "C:/Users/zhaol/Desktop/codexex/polymer_analysis/Aerogel_SEM/20230824_15p_18.tif",
    "C:/Users/zhaol/Desktop/codexex/polymer_analysis/Aerogel_SEM/20230831_11p_17.tif"
]

sns.set(style="whitegrid", palette="muted")
plt.rcParams['font.family'] = ['SimHei', 'Arial', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['figure.figsize'] = (12, 8)
def imread_gray_8bit(img_path: str) -> np.ndarray:
    """读取图像并转为8位灰度图"""
    img = io.imread(img_path, as_gray=True)
    return (img * 255).astype(np.uint8)

def enhance_contrast(img: np.ndarray) -> np.ndarray:
    """增强对比度（使用CLAHE）"""
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    return clahe.apply(img)

def denoise(img: np.ndarray) -> np.ndarray:
    """去噪（使用非局部均值去噪）"""
    return cv2.fastNlMeansDenoising(img, None, h=10, templateWindowSize=7, searchWindowSize=21)

def binarize_pores(img: np.ndarray) -> np.ndarray:
    """返回 True/False 二值图（孔隙=True）"""
    otsu = filters.threshold_otsu(img)
    binary = img < otsu
    # 极端阈值保护
    p = np.mean(binary)
    if p < 0.01 or p > 0.99:
        binary = img > otsu
    return remove_small_objects(binary, min_size=20)

# ---------- 主特征提取 ----------
def extract_porosity_features(img_path: str):
    """提取所有孔隙/骨架特征"""
    # 1. 读取-预处理-二值化
    img = imread_gray_8bit(img_path)
    img = enhance_contrast(img)
    img = denoise(img)
    binary = binarize_pores(img)

    # 2. 基础统计
    porosity = float(np.mean(binary))
    labeled, num_labels = measure.label(binary, connectivity=2, return_num=True)
    areas = [r.area for r in measure.regionprops(labeled)] or [0.0]

    # 3. 形态学
    def safe_mean(lst):
        return float(np.mean(lst)) if lst else np.nan

    props = measure.regionprops(labeled)
    ecc   = [r.eccentricity for r in props]
    asp   = [r.major_axis_length / max(r.minor_axis_length, 1e-6) for r in props]
    solid = [r.solidity for r in props]

    # 4. 骨架
    skeleton = skeletonize(binary)
    skel_density = float(np.sum(skeleton) / np.prod(binary.shape))

    # 端点/分叉点
    n = ndi.convolve(skeleton.astype(np.uint8), np.ones((3, 3)), mode='constant')
    end_pts   = skeleton & (n == 2)      # 骨架本身占 1，邻域 1 → 总和 2
    branch_pts= skeleton & (n >= 4)
    n_end   = int(np.sum(end_pts))
    n_branch= int(np.sum(branch_pts))

    # 5. 分形维数
    fractal_dim = calculate_fractal_dimension(skeleton.astype(bool))

    return {
        'porosity': porosity,
        'avg_pore_size': safe_mean(areas),
        'median_pore_size': float(np.median(areas)),
        'std_pore_size': float(np.std(areas)),
        'circularity': safe_mean(ecc),
        'aspect_ratio': safe_mean(asp),
        'solidity': safe_mean(solid),
        'skeleton_length_density': skel_density,
        'num_endpoints': n_end,
        'num_branchpoints': n_branch,
        'fractal_dimension': fractal_dim
    }




# 图像处理：提取孔隙特征
# 因为下面的部分连通性很差，不会被检测到，所以这里就不再进行裁剪或者检测了

# 计算分形维数的函数（基于盒计数法）
def calculate_fractal_dimension(binary_img: np.ndarray) -> float:
    """
    简化版盒计数法，输入为二值骨架 (True/False)。
    """
    Z = binary_img.astype(np.uint8)
    sizes = 2 ** np.arange(1, int(np.log2(min(Z.shape))) - 1, dtype=int)
    counts = []
    for size in sizes:
        box = (Z[::size, ::size] > 0).sum()
        counts.append(box)
    coeffs = np.polyfit(np.log(sizes), np.log(counts), 1)
    return -coeffs[0]

def calculate_fractal_dimension(binary_img: np.ndarray) -> float:
    """
    盒计数法计算二值图的分形维数。
    输入:
        binary_img : 2-D ndarray, 0/1 或 True/False 均可
    返回:
        float : 分形维数 D
    """
    # 保证是 0-1 二值图
    Z = (binary_img > 0).astype(np.uint8)

    # 2^k 的边长序列，从 1 到图像最短边的一半
    max_k = int(np.log2(min(Z.shape))) - 1
    sizes = 2 ** np.arange(1, max_k + 1)      # [2,4,8,...,2^max_k]

    counts = []
    for size in sizes:
        # 用 view_as_blocks 把图像切成 size×size 的盒子，统计“非空”盒子数
        from skimage.util import view_as_blocks
        if Z.shape[0] % size != 0 or Z.shape[1] % size != 0:
            # 裁剪到能整除
            h, w = (Z.shape[0] // size) * size, (Z.shape[1] // size) * size
            Z_crop = Z[:h, :w]
        else:
            Z_crop = Z
        blocks = view_as_blocks(Z_crop, block_shape=(size, size))
        # 只要盒子里有 1 就计数
        n = np.sum(blocks.any(axis=(2, 3)))
        counts.append(n)

    # 线性拟合 log(size) vs log(count)
    log_sizes = np.log(sizes)
    log_counts = np.log(counts)
    coeffs = np.polyfit(log_sizes, log_counts, 1)
    fractal_dimension = -coeffs[0]   # 因为 log N = -D log ε + C
    return fractal_dimension

def validate_data(pva_df):
    try:
        pva_cols = ['concentration', 'density', 'volume_shrinkage', 'modulus', 'modulus_std', 'transmittance']
        if not all(col in pva_df.columns for col in pva_cols):
            logger.error(f"PVA气凝胶数据缺少必要列: {set(pva_cols) - set(pva_df.columns)}")
            return False
        if not pva_df['concentration'].dtype in [np.float64, np.int64]:
            logger.error(f"PVA气凝胶数据的浓度列必须为数值类型")
            return False
        if not (pva_df['concentration'] > 0).all():
            logger.error(f"PVA气凝胶数据包含非正浓度值")
            return False
        missing = pva_df.isnull().sum().sum()
        if missing > 0:
            logger.warning(f"PVA气凝胶数据包含{missing}个缺失值")
        logger.info("数据验证通过")
        return True
    except Exception as e:
        logger.error(f"数据验证失败: {e}")
        return False
def expand_concentration_range(df: pd.DataFrame,
                               target_samples: int,
                               conc_col: str = 'concentration') -> pd.DataFrame:
    """
    把浓度范围扩展到 target_samples 行。
    1. 如果行数 ≥ target_samples，直接返回；
    2. 否则，以浓度为自变量，对其余数值列做线性插值。
    """
    if len(df) >= target_samples:
        return df.reset_index(drop=True)

    # 按浓度排序
    df = df.sort_values(conc_col).reset_index(drop=True)

    # 构造新的浓度轴
    new_conc = np.linspace(df[conc_col].min(), df[conc_col].max(), target_samples)

    # 逐列插值
    interp_df = {conc_col: new_conc}
    for col in df.columns:
        if col == conc_col:
            continue
        interp_df[col] = np.interp(new_conc, df[conc_col], df[col])

    return pd.DataFrame(interp_df)
def load_and_preprocess_data(image_paths, expand=True, target_samples=200):
    start_time = time.time()
    cache_file = Path("results/cached_dataset.csv")
    if cache_file.exists():
        logger.info("加载缓存数据集")
        try:
            final_df = pd.read_csv(cache_file)
            logger.info(f"从缓存加载数据集，耗时{time.time() - start_time:.2f}秒")
            return final_df
        except Exception as e:
            logger.warning(f"缓存加载失败: {e}，重新处理数据")
    try:
        pva_df = pd.read_excel("PVA Aerogel Data.xlsx", sheet_name="Sheet2")
        pva_df.columns = ['concentration', 'density', 'volume_shrinkage', 'modulus', 'modulus_std', 'transmittance']
        if not validate_data(pva_df):
            return None
        # 提取图像特征并将其与浓度相匹配
        porosity_features = []
        for img_path in image_paths:
            features = extract_porosity_features(img_path)
            stem = Path(img_path).stem
            features['concentration'] = float(stem.split('_')[1].split('p')[0])  # 假设图片文件名包含浓度信息
            porosity_features.append(features)

        # 将图像特征整合到PVA DataFrame中
        porosity_df = pd.DataFrame(porosity_features)
        pva_df = pd.merge(pva_df, porosity_df, on='concentration', how='left')

        imputer = KNNImputer(n_neighbors=3)
        pva_df[['modulus', 'modulus_std']] = imputer.fit_transform(pva_df[['modulus', 'modulus_std']])

        # 扩展浓度范围
        if expand:
            logger.info(f"原始样本数: {len(pva_df)}")
            pva_df = expand_concentration_range(pva_df, target_samples)
            logger.info(f"扩展后样本数: {len(pva_df)}")

        pva_df.to_csv(cache_file, index=False)
        logger.info(f"数据预处理完成，缓存保存至{cache_file}，耗时{time.time() - start_time:.2f}秒")
        return pva_df
    except FileNotFoundError as e:
        logger.error(f"数据文件未找到: {e}")
        return None
    except Exception as e:
        logger.error(f"数据加载或预处理失败: {e}")
        return None

# 执行数据分析：可以在此进行进一步的建模或其他分析
def analyze_pva_features(pva_df):
    logger.info("PVA气凝胶数据的特征分析：" + str(pva_df.describe()))
    return pva_df
if __name__ == "__main__":
     print(">>> 脚本已开始运行 <<<")
     df = load_and_preprocess_data(image_paths, expand=True, target_samples=200)
     if df is not None:
        df = analyze_pva_features(df)

        # 自动保存到 results/ 目录
        save_path = RESULT_DIR / f"pva_features_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv"
        df.to_csv(save_path, index=False, encoding='utf-8-sig')
        logger.info(f"特征表格已保存至: {save_path}")
logger.info("=== 测试日志 ===")
logging.shutdown()          # 强制把缓冲区的内容刷到硬盘
log_path = RESULT_DIR / "aerogel_analysis.log"
logging.basicConfig(
    filename=log_path,
)
print("日志文件绝对路径：", log_path.resolve())
